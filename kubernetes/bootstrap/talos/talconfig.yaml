---
# yaml-language-server: $schema=https://raw.githubusercontent.com/budimanjojo/talhelper/master/pkg/config/schemas/talconfig.json
clusterName: &cluster home-kubernetes
# renovate: datasource=github-releases depName=siderolabs/talos
talosVersion: v1.10.3
# renovate: datasource=github-releases depName=kubernetes/kubernetes
kubernetesVersion: v1.32.3

endpoint: https://10.0.10.30:6443
clusterPodNets:
  - "10.69.0.0/16"
clusterSvcNets:
  - "10.96.0.0/16"
additionalApiServerCertSans: &sans
  - "10.0.10.30"
  - 127.0.0.1 # KubePrism
  - "talos.flyingfox-decibel.ts.net"
additionalMachineCertSans: *sans
cniConfig:
  name: none


nodes:
  - hostname: "jormungandr1"
    ipAddress: "10.0.10.31"
    installDisk: "/dev/sda"
    controlPlane: true
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "e4:5f:01:*"
        dhcp: true
        mtu: 1500
        vip:
          ip: "10.0.10.30"
    schematic: &pischematic
      customization:
        systemExtensions:
          officialExtensions:
            - siderolabs/binfmt-misc
            - siderolabs/iscsi-tools
            - siderolabs/tailscale
    extensionServices:
    - name: tailscale
      environment:
      - TS_AUTHKEY=${SECRET_TS_AUTHKEY}

  - hostname: "jormungandr2"
    ipAddress: "10.0.10.32"
    installDisk: "/dev/sda"
    controlPlane: true
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "e4:5f:01:*"
        dhcp: true
        mtu: 1500
        vip:
          ip: "10.0.10.30"
    schematic: *pischematic
    extensionServices:
    - name: tailscale
      environment:
      - TS_AUTHKEY=${SECRET_TS_AUTHKEY}

  - hostname: "jormungandr3"
    ipAddress: "10.0.10.33"
    installDisk: "/dev/sda"
    controlPlane: true
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "e4:5f:01:*"
        dhcp: true
        mtu: 1500
        vip:
          ip: "10.0.10.30"
    schematic: *pischematic
    extensionServices:
    - name: tailscale
      environment:
      - TS_AUTHKEY=${SECRET_TS_AUTHKEY}

  - hostname: "jormungandr4"
    ipAddress: "10.0.10.34"
    installDisk: "/dev/sda"
    controlPlane: false
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "e4:5f:01:*"
        dhcp: true
        mtu: 1500
    schematic: *pischematic
    extensionServices:
    - name: tailscale
      environment:
      - TS_AUTHKEY=${SECRET_TS_AUTHKEY}

  - hostname: "brokkr01"
    ipAddress: "10.0.10.38"
    installDisk: "/dev/sda"
    controlPlane: false
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "bc:24:11:*"
        dhcp: true
        mtu: 9000
    schematic: &schematic
      customization:
        systemExtensions:
          officialExtensions:
            - siderolabs/amd-ucode
            - siderolabs/amdgpu
            - siderolabs/binfmt-misc
            - siderolabs/iscsi-tools
            - siderolabs/qemu-guest-agent
            - siderolabs/tailscale
    extensionServices:
    - name: tailscale
      environment:
      - TS_AUTHKEY=${SECRET_TS_AUTHKEY}

  - hostname: "brokkr02"
    ipAddress: "10.0.10.39"
    installDisk: "/dev/sda"
    controlPlane: false
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "bc:24:11:*"
        dhcp: true
        mtu: 9000
    schematic: *schematic
    extensionServices:
    - name: tailscale
      environment:
      - TS_AUTHKEY=${SECRET_TS_AUTHKEY}

  - hostname: "freyja01"
    ipAddress: "10.0.10.41"
    installDisk: "/dev/vda"
    controlPlane: false
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "00:a0:98:*"
        dhcp: true
        mtu: 9000
    schematic:
      customization:
        systemExtensions:
          officialExtensions:
            - siderolabs/amd-ucode
            - siderolabs/amdgpu
            - siderolabs/binfmt-misc
            - siderolabs/iscsi-tools
            - siderolabs/nonfree-kmod-nvidia-production
            - siderolabs/nvidia-container-toolkit-production
            - siderolabs/qemu-guest-agent
            - siderolabs/tailscale
    extensionServices:
    - name: tailscale
      environment:
      - TS_AUTHKEY=${SECRET_TS_AUTHKEY}
    patches:
      - |-
        - op: add
          path: /machine/kernel
          value:
            modules:
              - name: nvidia
              - name: nvidia_uvm
              - name: nvidia_drm
              - name: nvidia_modeset
      - |-
        - op: add
          path: /machine/sysctls
          value:
            net.core.bpf_jit_harden: 1

patches:
  # Configure containerd
  - |-
    machine:
      files:
        - op: create
          path: /etc/cri/conf.d/20-customization.part
          content: |-
            [plugins."io.containerd.grpc.v1.cri"]
              enable_unprivileged_ports = true
              enable_unprivileged_icmp = true
            [plugins."io.containerd.grpc.v1.cri".containerd]
              discard_unpacked_layers = false
            [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
              discard_unpacked_layers = false

  # Disable search domain everywhere
  - |-
    machine:
      network:
        disableSearchDomain: true

  # Enable cluster discovery
  - |-
    cluster:
      discovery:
        registries:
          service:
            disabled: false

  # Configure kubelet
  - |-
    machine:
      kubelet:
        extraArgs:
          image-gc-low-threshold: 50
          image-gc-high-threshold: 55
        nodeIP:
          validSubnets:
            - "10.0.10.0/24"

  # Force nameserver
  - |-
    machine:
      network:
        nameservers:

  # Configure NTP
  - |-
    machine:
      time:
        disabled: false
        servers:
          - chronos.funb.us
          - pve01.funb.us
          - pve02.funb.us
          - pve03.funb.us
          - ntp1.wiktel.com
          - ntp2.wiktel.com
          - time.cloudflare.com

  # Custom sysctl settings
  - |-
    machine:
      sysctls:
        fs.inotify.max_queued_events: 65536
        fs.inotify.max_user_watches: 524288
        fs.inotify.max_user_instances: 8192
        net.core.rmem_max: "5000000"
        net.core.wmem_max: "5000000"

  # Mount openebs-hostpath in kubelet
  - |-
    machine:
      kubelet:
        extraMounts:
          - destination: /var/openebs/local
            type: bind
            source: /var/openebs/local
            options:
              - bind
              - rshared
              - rw

controlPlane:
  patches:
    # Cluster configuration
    - |-
      cluster:
        allowSchedulingOnMasters: false
        controllerManager:
          extraArgs:
            bind-address: 0.0.0.0
        proxy:
          disabled: true
        scheduler:
          extraArgs:
            bind-address: 0.0.0.0

    # ETCD configuration
    - |-
      cluster:
        etcd:
          extraArgs:
            listen-metrics-urls: http://0.0.0.0:2381
          advertisedSubnets:
            - "10.0.10.0/24"

    # Disable default API server admission plugins.
    - |-
      - op: remove
        path: /cluster/apiServer/admissionControl

    # Enable K8s Talos API Access
    - |-
      machine:
        features:
          kubernetesTalosAPIAccess:
            enabled: true
            allowedRoles:
              - os:admin
              - os:etcd:backup
            allowedKubernetesNamespaces:
              - system-upgrade
              - kube-system


